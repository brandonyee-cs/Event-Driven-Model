{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA Approval Event Analysis - Always Buy Strategy Evaluation\n",
    "\n",
    "This notebook analyzes the performance of a naive \"always buy\" strategy compared to the TimeSeriesRidge and XGBoostDecile models for FDA drug approval events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Metrics for performance analysis\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# Import the FDA analysis modules\n",
    "from analysis import DataLoader, FeatureEngineer, Analysis\n",
    "from analysis import TimeSeriesRidge, XGBoostDecileModel\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('results/all_buy_fda', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Always Buy Model\n",
    "\n",
    "First, let's define a naive model that always predicts buying (positive return)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlwaysBuyModel:\n",
    "    \"\"\"\n",
    "    A naive model that always predicts buying (positive return).\n",
    "    This serves as a baseline to compare with more sophisticated models.\n",
    "    \"\"\"\n",
    "    def __init__(self, prediction_value=0.01):\n",
    "        \"\"\"\n",
    "        Initialize the model.\n",
    "        \n",
    "        Parameters:\n",
    "        prediction_value (float): The constant positive return prediction value\n",
    "        \"\"\"\n",
    "        self.prediction_value = prediction_value\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit method (does nothing as this is a naive model)\"\"\"\n",
    "        # Simply store the mean of the target for reference\n",
    "        self.mean_target = np.mean(y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Always predict the same positive return value\"\"\"\n",
    "        return np.full(len(X), self.prediction_value)\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        \"\"\"Return model parameters (for compatibility with sklearn)\"\"\"\n",
    "        return {'prediction_value': self.prediction_value}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data\n",
    "\n",
    "Load the FDA and stock data, create the target variable, and calculate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths to data files - update these to your local paths\n",
    "#stock_path = '/home/brand/MIT/DMPS-Data/fda-intraday/crsp-fda-2020-2025.csv'  # Stock data\n",
    "fda_path = '/home/brand/MIT/DMPS-Data/fda-scrapped/fda_ticker_list_2000_to_2024.csv'  # FDA approval data\n",
    "stock_paths = []\n",
    "\n",
    "# For multiple stock files\n",
    "data_loader = DataLoader(\n",
    "    fda_path='path/to/fda_data.csv',\n",
    "    stock_paths=[\n",
    "        'path/to/stock_data1.csv',\n",
    "        'path/to/stock_data2.csv',\n",
    "        'path/to/stock_data3.csv',\n",
    "        'path/to/stock_data4.csv'\n",
    "    ],\n",
    "    window_days=60\n",
    ")\n",
    "\n",
    "# For a single stock file (backward compatible)\n",
    "#data_loader = DataLoader(\n",
    "#    fda_path=fda_path,\n",
    "#    stock_paths=stock_path,\n",
    "#    window_days=60\n",
    "#)\n",
    "# Initialize feature engineer with 5-day prediction window\n",
    "feature_engineer = FeatureEngineer(prediction_window=5)\n",
    "\n",
    "# Initialize analysis\n",
    "analysis = Analysis(data_loader, feature_engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "print(\"Loading and preparing data...\")\n",
    "data = analysis.load_and_prepare_data()\n",
    "\n",
    "# Display data summary\n",
    "print(\"\\nData Overview:\")\n",
    "print(f\"- Total observations: {len(data)}\")\n",
    "print(f\"- Unique FDA events: {data[['ticker', 'Approval Date']].drop_duplicates().shape[0]}\")\n",
    "print(f\"- Unique tickers: {data['ticker'].nunique()}\")\n",
    "print(f\"- Date range: {data['date'].min()} to {data['date'].max()}\")\n",
    "\n",
    "# Train the original models\n",
    "print(\"Training original models...\")\n",
    "original_models = analysis.train_models(test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Always Buy Strategy\n",
    "\n",
    "Now let's implement and evaluate the naive \"always buy\" strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to calculate performance metrics\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.02):\n",
    "    \"\"\"\n",
    "    Calculate annualized Sharpe ratio\n",
    "    \n",
    "    Parameters:\n",
    "    returns (array-like): Series of returns (assumed to be daily)\n",
    "    risk_free_rate (float): Annual risk-free rate (default 2%)\n",
    "    \n",
    "    Returns:\n",
    "    float: Annualized Sharpe ratio\n",
    "    \"\"\"\n",
    "    # Convert annual risk-free rate to daily\n",
    "    daily_rf = (1 + risk_free_rate) ** (1/252) - 1\n",
    "    \n",
    "    # Calculate excess returns\n",
    "    excess_returns = returns - daily_rf\n",
    "    \n",
    "    # Calculate annualized Sharpe ratio (assuming daily returns)\n",
    "    sharpe = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252)\n",
    "    \n",
    "    return sharpe\n",
    "\n",
    "def evaluate_model_performance(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance with comprehensive metrics\"\"\"\n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Basic metrics\n",
    "    metrics = {\n",
    "        \"Train MSE\": mean_squared_error(y_train, y_pred_train),\n",
    "        \"Test MSE\": mean_squared_error(y_test, y_pred_test),\n",
    "        \"Train RMSE\": np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "        \"Test RMSE\": np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "        \"Train MAE\": mean_absolute_error(y_train, y_pred_train),\n",
    "        \"Test MAE\": mean_absolute_error(y_test, y_pred_test),\n",
    "        \"Train R²\": r2_score(y_train, y_pred_train),\n",
    "        \"Test R²\": r2_score(y_test, y_pred_test),\n",
    "    }\n",
    "    \n",
    "    # Correlation metrics\n",
    "    if not all(y_pred_test == y_pred_test[0]):  # Check if predictions are not all the same\n",
    "        pearson_corr, pearson_p = pearsonr(y_test, y_pred_test)\n",
    "        spearman_corr, spearman_p = spearmanr(y_test, y_pred_test)\n",
    "        metrics[\"Pearson Correlation\"] = pearson_corr\n",
    "        metrics[\"Pearson p-value\"] = pearson_p\n",
    "        metrics[\"Spearman Correlation\"] = spearman_corr\n",
    "        metrics[\"Spearman p-value\"] = spearman_p\n",
    "    else:  # For always-buy model where all predictions are the same\n",
    "        metrics[\"Pearson Correlation\"] = np.nan\n",
    "        metrics[\"Pearson p-value\"] = np.nan\n",
    "        metrics[\"Spearman Correlation\"] = np.nan\n",
    "        metrics[\"Spearman p-value\"] = np.nan\n",
    "    \n",
    "    # Directional accuracy (sign prediction)\n",
    "    direction_correct_test = np.sum(np.sign(y_pred_test) == np.sign(y_test))\n",
    "    metrics[\"Direction Accuracy\"] = direction_correct_test / len(y_test)\n",
    "    \n",
    "    # Calculate Sharpe ratio (strategy returns)\n",
    "    # For always-buy, this is just the actual returns since all predictions are positive\n",
    "    # For other models, this is sign(prediction) * actual return\n",
    "    strategy_returns = np.sign(y_pred_test) * y_test\n",
    "    metrics[\"Sharpe Ratio\"] = calculate_sharpe_ratio(strategy_returns)\n",
    "    \n",
    "    # For always-buy model, also calculate percentage of positive returns\n",
    "    metrics[\"Positive Returns %\"] = np.mean(y_test > 0) * 100\n",
    "    \n",
    "    # Count positive/negative actual returns to understand distribution\n",
    "    metrics[\"Positive Returns Count\"] = np.sum(y_test > 0)\n",
    "    metrics[\"Negative Returns Count\"] = np.sum(y_test < 0)\n",
    "    metrics[\"Zero Returns Count\"] = np.sum(y_test == 0)\n",
    "    metrics[\"Total Returns Count\"] = len(y_test)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{model_name} Model Performance:\")\n",
    "    print(f\"Test RMSE: {metrics['Test RMSE']:.6f}\")\n",
    "    print(f\"Test MAE: {metrics['Test MAE']:.6f}\")\n",
    "    print(f\"Test R²: {metrics['Test R²']:.6f}\")\n",
    "    print(f\"Direction Accuracy: {metrics['Direction Accuracy']:.2%}\")\n",
    "    print(f\"Positive Returns: {metrics['Positive Returns %']:.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {metrics['Sharpe Ratio']:.4f}\")\n",
    "    \n",
    "    return metrics, y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and evaluate the always-buy model\n",
    "# First, get the mean of the target in the training set to use as prediction value\n",
    "y_train_mean = np.mean(analysis.y_train)\n",
    "print(f\"Average return in training set: {y_train_mean:.6f}\")\n",
    "\n",
    "# Create always buy model with the mean return as prediction value\n",
    "always_buy_model = AlwaysBuyModel(prediction_value=abs(y_train_mean))\n",
    "always_buy_model.fit(analysis.X_train, analysis.y_train)\n",
    "\n",
    "# Add to models dictionary\n",
    "analysis.models['AlwaysBuy'] = always_buy_model\n",
    "\n",
    "# Evaluate all models including the always-buy model\n",
    "performance_metrics = {}\n",
    "test_predictions = {}\n",
    "\n",
    "for name, model in analysis.models.items():\n",
    "    metrics, y_pred = evaluate_model_performance(\n",
    "        model, analysis.X_train, analysis.y_train, analysis.X_test, analysis.y_test, name\n",
    "    )\n",
    "    performance_metrics[name] = metrics\n",
    "    test_predictions[name] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Comparison\n",
    "\n",
    "Let's compare the performance of all models including the always-buy strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "metrics_df = pd.DataFrame(performance_metrics)\n",
    "\n",
    "# Display key metrics\n",
    "key_metrics = [\n",
    "    \"Direction Accuracy\", \n",
    "    \"Sharpe Ratio\", \n",
    "    \"Test RMSE\", \n",
    "    \"Test MAE\", \n",
    "    \"Test R²\",\n",
    "    \"Positive Returns %\"\n",
    "]\n",
    "\n",
    "metrics_df.loc[key_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize directional accuracy comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics_df.columns, metrics_df.loc[\"Direction Accuracy\"] * 100)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{height:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Directional Accuracy Comparison')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.ylim(0, 100)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/all_buy_fda/directional_accuracy_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Sharpe ratio comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(metrics_df.columns, metrics_df.loc[\"Sharpe Ratio\"])\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "            f'{height:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Sharpe Ratio Comparison')\n",
    "plt.ylabel('Sharpe Ratio')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/all_buy_fda/sharpe_ratio_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Added Analysis\n",
    "\n",
    "Let's calculate how much value the more complex models add relative to the always-buy strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate value added by each model relative to always-buy\n",
    "always_buy_metrics = performance_metrics['AlwaysBuy']\n",
    "value_added = {}\n",
    "\n",
    "for name, metrics in performance_metrics.items():\n",
    "    if name != 'AlwaysBuy':\n",
    "        # Calculate improvement in key metrics\n",
    "        value_added[name] = {\n",
    "            'Direction Accuracy Improvement': metrics['Direction Accuracy'] - always_buy_metrics['Direction Accuracy'],\n",
    "            'Sharpe Ratio Improvement': metrics['Sharpe Ratio'] - always_buy_metrics['Sharpe Ratio'],\n",
    "            'RMSE Improvement': always_buy_metrics['Test RMSE'] - metrics['Test RMSE'],\n",
    "            'MAE Improvement': always_buy_metrics['Test MAE'] - metrics['Test MAE'],\n",
    "            'R² Improvement': metrics['Test R²'] - always_buy_metrics['Test R²']\n",
    "        }\n",
    "\n",
    "# Create value added DataFrame\n",
    "value_added_df = pd.DataFrame(value_added)\n",
    "value_added_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize value added in directional accuracy and Sharpe ratio\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "# Directional Accuracy Improvement\n",
    "bars1 = ax1.bar(value_added_df.columns, value_added_df.loc['Direction Accuracy Improvement'] * 100)\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.2f}%', ha='center', va='bottom' if height > 0 else 'top')\n",
    "ax1.set_title('Improvement in Directional Accuracy vs Always-Buy')\n",
    "ax1.set_ylabel('Percentage Points Improvement')\n",
    "ax1.axhline(y=0, color='r', linestyle='--')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Sharpe Ratio Improvement\n",
    "bars2 = ax2.bar(value_added_df.columns, value_added_df.loc['Sharpe Ratio Improvement'])\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "             f'{height:.2f}', ha='center', va='bottom' if height > 0 else 'top')\n",
    "ax2.set_title('Improvement in Sharpe Ratio vs Always-Buy')\n",
    "ax2.set_ylabel('Sharpe Ratio Improvement')\n",
    "ax2.axhline(y=0, color='r', linestyle='--')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/all_buy_fda/value_added_comparison.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Distribution Analysis\n",
    "\n",
    "Let's analyze the distribution of returns to better understand why the always-buy strategy performs the way it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of actual returns\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(analysis.y_test, kde=True, bins=50)\n",
    "plt.axvline(x=0, color='r', linestyle='--', label='Zero Return')\n",
    "plt.axvline(x=np.mean(analysis.y_test), color='g', linestyle='-', label=f'Mean Return ({np.mean(analysis.y_test):.4f})')\n",
    "plt.axvline(x=np.median(analysis.y_test), color='b', linestyle='-.', label=f'Median Return ({np.median(analysis.y_test):.4f})')\n",
    "plt.title('Distribution of Returns in Test Set')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/all_buy_fda/return_distribution.png')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics about returns\n",
    "print(\"Return Statistics:\")\n",
    "print(f\"Mean Return: {np.mean(analysis.y_test):.6f}\")\n",
    "print(f\"Median Return: {np.median(analysis.y_test):.6f}\")\n",
    "print(f\"Standard Deviation: {np.std(analysis.y_test):.6f}\")\n",
    "print(f\"Minimum Return: {np.min(analysis.y_test):.6f}\")\n",
    "print(f\"Maximum Return: {np.max(analysis.y_test):.6f}\")\n",
    "print(f\"Positive Returns: {np.sum(analysis.y_test > 0)} ({np.mean(analysis.y_test > 0):.2%})\")\n",
    "print(f\"Negative Returns: {np.sum(analysis.y_test < 0)} ({np.mean(analysis.y_test < 0):.2%})\")\n",
    "print(f\"Zero Returns: {np.sum(analysis.y_test == 0)} ({np.mean(analysis.y_test == 0):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Returns Around FDA Approval Date\n",
    "\n",
    "Let's examine average returns around FDA approval dates to understand if there's a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average returns around approval date\n",
    "print(\"Analyzing returns around approval dates...\")\n",
    "\n",
    "# Define window for analysis\n",
    "pre_days = 10\n",
    "post_days = 20\n",
    "\n",
    "# Initialize DataFrame for aligned returns\n",
    "aligned_returns = pd.DataFrame(\n",
    "    index=range(-pre_days, post_days + 1),\n",
    "    columns=['avg_ret', 'cum_ret', 'count', 'pos_count', 'neg_count']\n",
    ").fillna(0)\n",
    "\n",
    "# Collect returns for each day relative to approval\n",
    "for ticker, approval_date in data[['ticker', 'Approval Date']].drop_duplicates().values:\n",
    "    event_data = data[(data['ticker'] == ticker) & (data['Approval Date'] == approval_date)].copy()\n",
    "    \n",
    "    # Only include events with sufficient data\n",
    "    if len(event_data) < (pre_days + post_days + 1):\n",
    "        continue\n",
    "    \n",
    "    # Get returns indexed by days to approval\n",
    "    for day in range(-pre_days, post_days + 1):\n",
    "        day_data = event_data[event_data['days_to_approval'] == day]\n",
    "        if not day_data.empty:\n",
    "            ret = day_data['ret'].iloc[0]\n",
    "            aligned_returns.loc[day, 'avg_ret'] += ret\n",
    "            aligned_returns.loc[day, 'count'] += 1\n",
    "            if ret > 0:\n",
    "                aligned_returns.loc[day, 'pos_count'] += 1\n",
    "            elif ret < 0:\n",
    "                aligned_returns.loc[day, 'neg_count'] += 1\n",
    "\n",
    "# Calculate averages and cumulative returns\n",
    "aligned_returns['avg_ret'] = aligned_returns['avg_ret'] / aligned_returns['count']\n",
    "aligned_returns['cum_ret'] = (1 + aligned_returns['avg_ret']).cumprod() - 1\n",
    "aligned_returns['pos_pct'] = aligned_returns['pos_count'] / aligned_returns['count'] * 100\n",
    "\n",
    "# Display the aligned returns\n",
    "aligned_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot average returns and percentage of positive returns around approval date\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15))\n",
    "\n",
    "# Daily Average Returns\n",
    "ax1.bar(aligned_returns.index, aligned_returns['avg_ret'] * 100)\n",
    "ax1.axvline(x=0, color='r', linestyle='--', label='FDA Approval Date')\n",
    "ax1.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax1.set_title('Average Daily Returns Around FDA Approval Date')\n",
    "ax1.set_ylabel('Return (%)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Cumulative Returns\n",
    "ax2.plot(aligned_returns.index, aligned_returns['cum_ret'] * 100, 'b-', linewidth=2)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', label='FDA Approval Date')\n",
    "ax2.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax2.set_title('Average Cumulative Returns Around FDA Approval Date')\n",
    "ax2.set_ylabel('Cumulative Return (%)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# Percentage of Positive Returns\n",
    "ax3.bar(aligned_returns.index, aligned_returns['pos_pct'])\n",
    "ax3.axvline(x=0, color='r', linestyle='--', label='FDA Approval Date')\n",
    "ax3.axhline(y=50, color='k', linestyle='-', alpha=0.3, label='50% Threshold')\n",
    "ax3.set_title('Percentage of Positive Returns Around FDA Approval Date')\n",
    "ax3.set_xlabel('Days Relative to Approval')\n",
    "ax3.set_ylabel('Positive Returns (%)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/all_buy_fda/returns_around_approval.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers to Key Questions\n",
    "\n",
    "Based on our analysis, let's answer the key questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the directional accuracy if you have a naive model that always buys?\n",
    "\n",
    "The directional accuracy of the always-buy strategy is equal to the percentage of positive returns in the dataset. From our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Directional accuracy of always-buy model: {metrics_df.loc['Direction Accuracy', 'AlwaysBuy']:.2%}\")\n",
    "print(f\"Percentage of positive returns: {metrics_df.loc['Positive Returns %', 'AlwaysBuy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curious since most are approved\n",
    "\n",
    "This observation is about whether most FDA approvals lead to positive stock returns. Let's analyze the data around FDA approval dates specifically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze returns specifically on FDA approval days (day 0)\n",
    "approval_day_data = data[data['days_to_approval'] == 0]\n",
    "approval_day_returns = approval_day_data['ret']\n",
    "\n",
    "print(\"FDA Approval Day Return Statistics:\")\n",
    "print(f\"Number of approval events: {len(approval_day_returns)}\")\n",
    "print(f\"Mean return on approval day: {np.mean(approval_day_returns):.6f}\")\n",
    "print(f\"Median return on approval day: {np.median(approval_day_returns):.6f}\")\n",
    "print(f\"Positive returns: {np.sum(approval_day_returns > 0)} ({np.mean(approval_day_returns > 0):.2%})\")\n",
    "print(f\"Negative returns: {np.sum(approval_day_returns < 0)} ({np.mean(approval_day_returns < 0):.2%})\")\n",
    "print(f\"Zero returns: {np.sum(approval_day_returns == 0)} ({np.mean(approval_day_returns == 0):.2%})\")\n",
    "\n",
    "# Also look at returns in the days following approval\n",
    "post_approval_data = data[(data['days_to_approval'] > 0) & (data['days_to_approval'] <= 5)]\n",
    "post_approval_returns = post_approval_data.groupby(['ticker', 'Approval Date'])['ret'].sum()\n",
    "\n",
    "print(\"\\nCumulative 5-day Post-Approval Return Statistics:\")\n",
    "print(f\"Number of approval events: {len(post_approval_returns)}\")\n",
    "print(f\"Mean 5-day return after approval: {np.mean(post_approval_returns):.6f}\")\n",
    "print(f\"Median 5-day return after approval: {np.median(post_approval_returns):.6f}\")\n",
    "print(f\"Positive 5-day returns: {np.sum(post_approval_returns > 0)} ({np.mean(post_approval_returns > 0):.2%})\")\n",
    "print(f\"Negative 5-day returns: {np.sum(post_approval_returns < 0)} ({np.mean(post_approval_returns < 0):.2%})\")\n",
    "print(f\"Zero 5-day returns: {np.sum(post_approval_returns == 0)} ({np.mean(post_approval_returns == 0):.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we add value relative to always buying?\n",
    "\n",
    "To answer this question, we need to compare the more sophisticated models with the always-buy benchmark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the value added\n",
    "print(\"Value Added by Sophisticated Models vs. Always-Buy Strategy:\")\n",
    "for model in value_added_df.columns:\n",
    "    print(f\"\\n{model} Model:\")\n",
    "    print(f\"  Direction Accuracy Improvement: {value_added_df.loc['Direction Accuracy Improvement', model] * 100:.2f} percentage points\")\n",
    "    print(f\"  Sharpe Ratio Improvement: {value_added_df.loc['Sharpe Ratio Improvement', model]:.4f}\")\n",
    "    print(f\"  RMSE Improvement: {value_added_df.loc['RMSE Improvement', model]:.6f}\")\n",
    "    print(f\"  MAE Improvement: {value_added_df.loc['MAE Improvement', model]:.6f}\")\n",
    "    print(f\"  R² Improvement: {value_added_df.loc['R² Improvement', model]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the sharpe of always buying?\n",
    "\n",
    "Let's calculate the Sharpe ratio of the always-buy strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Sharpe ratio of the always-buy model\n",
    "always_buy_sharpe = metrics_df.loc[\"Sharpe Ratio\", \"AlwaysBuy\"]\n",
    "print(f\"Sharpe ratio of always-buy strategy: {always_buy_sharpe:.4f}\")\n",
    "\n",
    "# Compare with other models\n",
    "for name in metrics_df.columns:\n",
    "    if name != \"AlwaysBuy\":\n",
    "        sharpe = metrics_df.loc[\"Sharpe Ratio\", name]\n",
    "        diff = sharpe - always_buy_sharpe\n",
    "        print(f\"{name} Sharpe ratio: {sharpe:.4f} (difference: {diff:+.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
